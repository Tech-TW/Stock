import streamlit as st
import pandas as pd
import requests
from io import BytesIO
import chardet

st.set_page_config(page_title="Upload Data", page_icon="ğŸ“¥", layout="wide")

st.title("ğŸ“¥ Import Data")
st.markdown("è«‹é¸æ“‡è³‡æ–™ä¾†æºï¼šæœ¬æ©Ÿæª”æ¡ˆä¸Šå‚³ æˆ– é›²ç«¯é€£çµåŒ¯å…¥ã€‚")

# ä½¿ç”¨ Tabs åˆ†é›¢é‚è¼¯ï¼Œä»‹é¢æ›´æ¸…çˆ½
tab1, tab2 = st.tabs(["ğŸ“‚ Upload File (CSV/Excel)", "â˜ï¸ Import from URL"])

# ========= å¿«å–è®€æª”å‡½å¼ =========
@st.cache_data(show_spinner=False)
def load_data_from_bytes(file_bytes, filename):
    """é€šç”¨è®€æª”é‚è¼¯ï¼šæ ¹æ“šå‰¯æª”åè‡ªå‹•åˆ¤æ–·è§£ææ–¹å¼"""
    try:
        if filename.lower().endswith(".csv"):
            # è‡ªå‹•åµæ¸¬ç·¨ç¢¼
            enc = chardet.detect(file_bytes).get("encoding") or "utf-8"
            return pd.read_csv(BytesIO(file_bytes), encoding=enc)
        else:
            # Excel
            return pd.read_excel(BytesIO(file_bytes))
    except Exception as e:
        raise ValueError(f"è§£æå¤±æ•—: {e}")

# ========= Tab 1: æœ¬æ©Ÿä¸Šå‚³ =========
with tab1:
    uploaded_file = st.file_uploader(
        "Drag and drop file here",
        type=["csv", "xlsx", "xls"],
        help="æ”¯æ´ CSV èˆ‡ Excel æ ¼å¼"
    )

    if uploaded_file is not None:
        try:
            with st.spinner("è®€å–æª”æ¡ˆä¸­..."):
                # è®€å– bytes
                bytes_data = uploaded_file.getvalue()
                df = load_data_from_bytes(bytes_data, uploaded_file.name)
                
                # æˆåŠŸè™•ç†
                st.session_state["uploaded_df"] = df
                st.toast(f"æˆåŠŸè¼‰å…¥: {uploaded_file.name}", icon="âœ…")
                st.success(f"File **{uploaded_file.name}** uploaded successfully!")
        except Exception as e:
            st.error(f"Error reading file: {e}")

# ========= Tab 2: URL åŒ¯å…¥ =========
with tab2:
    st.info("ğŸ’¡ æç¤ºï¼šé©ç”¨æ–¼ GitHub Raw é€£çµæˆ–å…¬é–‹çš„é›²ç«¯æª”æ¡ˆé€£çµã€‚")
    url = st.text_input("Paste file URL", placeholder="https://raw.githubusercontent.com/...")
    
    if st.button("ğŸš€ Fetch Data", use_container_width=True):
        if not url:
            st.warning("è«‹è¼¸å…¥ URL")
        else:
            try:
                with st.spinner("ä¸‹è¼‰ä¸¦è§£æä¸­..."):
                    r = requests.get(url, timeout=30)
                    r.raise_for_status()
                    
                    # å˜—è©¦å¾ URL æ¨æ–·æª”åï¼Œè‹¥ç„¡å‰‡é è¨­ç‚º csv
                    filename = url.split("/")[-1]
                    if "." not in filename: 
                        filename = "data.csv"
                        
                    df = load_data_from_bytes(r.content, filename)
                    
                    st.session_state["uploaded_df"] = df
                    st.toast("é›²ç«¯æª”æ¡ˆè¼‰å…¥æˆåŠŸï¼", icon="ğŸ‰")
                    st.success(f"Fetched from URL successfully! ({len(df)} rows)")
                    
            except Exception as e:
                st.error(f"Failed to fetch or parse URL: {e}")

# ========= è³‡æ–™é è¦½å€ (å…±ç”¨) =========
st.divider()

if "uploaded_df" in st.session_state and st.session_state["uploaded_df"] is not None:
    df_current = st.session_state["uploaded_df"]
    
    st.subheader("ğŸ“Š Data Preview")
    
    # ç°¡å–®çš„è³‡æ–™å“è³ªæª¢æŸ¥
    col_info1, col_info2 = st.columns(2)
    with col_info1:
        st.write(f"**Dimensions:** {df_current.shape[0]} rows Ã— {df_current.shape[1]} columns")
    with col_info2:
        missing_count = df_current.isnull().sum().sum()
        if missing_count > 0:
            st.warning(f"âš ï¸ åµæ¸¬åˆ° {missing_count} å€‹ç¼ºå€¼ (NaN)")
        else:
            st.success("âœ… ç„¡ç¼ºå€¼ (Clean Data)")

    st.dataframe(df_current.head(50), use_container_width=True)
    
    # å¼•å°ä¸‹ä¸€æ­¥
    st.markdown("""
    <div style="text-align: center; margin-top: 20px;">
        <p>è³‡æ–™ç¢ºèªç„¡èª¤å¾Œï¼Œè«‹é»æ“Šå·¦å´å´é‚Šæ¬„çš„ <b>Analyze</b> é€²è¡Œåˆ†æã€‚</p>
    </div>
    """, unsafe_allow_html=True)
else:
    st.caption("å°šæœªè¼‰å…¥ä»»ä½•è³‡æ–™ (No data loaded)")
